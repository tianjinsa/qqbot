# 配置项完整对照表

## ✅ 已添加到 `_conf_schema.json` 的配置项

### 基础配置
- ✅ `LAST_TIME` - 检测到推销后，回溯该用户消息的时间范围（分钟）
- ✅ `ADMIN_CHAT_ID` - 管理员群聊ID
- ✅ `SPAM_ALERT_MESSAGE` - 在原群聊发送的提示信息内容
- ✅ `MUTE_DURATION` - 禁言时长（秒）

### 白名单配置
- ✅ `WHITELIST_USERS` - 白名单用户列表
- ✅ `WHITELIST_GROUPS` - 白名单群聊列表

### 模型配置
- ✅ `LLM_SYSTEM_PROMPT` - 大模型系统提示词
- ✅ `TEXT_MODEL_ID` - 文本模型ID
- ✅ `TEXT_MODEL_BASE_URL` - 文本模型Base URL
- ✅ `TEXT_MODEL_API_KEY` - 文本模型API Key
- ✅ `VISION_MODEL_ID` - 视觉模型ID
- ✅ `VISION_MODEL_BASE_URL` - 视觉模型Base URL
- ✅ `VISION_MODEL_API_KEY` - 视觉模型API Key
- ✅ `MODEL_TIMEOUT` - 模型请求超时时间（秒）

### ✅ 新增的批量处理配置项
- ✅ `QUEUE_RATE_LIMIT` - 队列处理速率限制（秒）
- ✅ `BATCH_PROCESS_SIZE` - 批量处理大小
- ✅ `BATCH_MAX_TEXT_LENGTH` - 批量处理最大文本长度（字符数）
- ✅ `MAX_DETECTION_QUEUE_SIZE` - 最大检测队列大小

### ✅ 新增的AI模型增强配置项
- ✅ `TEXT_MODEL_TEMPERATURE` - 文本模型温度
- ✅ `TEXT_MODEL_THINKING_ENABLED` - 启用文本模型思考模式
- ✅ `VISION_MODEL_TEMPERATURE` - 视觉模型温度
- ✅ `VISION_MODEL_THINKING_ENABLED` - 启用视觉模型思考模式
- ✅ `VISION_MODEL_SYSTEM_PROMPT` - 视觉模型系统提示词

## 🔧 修复的配置项名称不一致问题

### 修复前
- 代码中使用: `GROUP_WHITELIST`
- 配置文件中: `WHITELIST_GROUPS`

### 修复后
- ✅ 统一使用: `WHITELIST_GROUPS`

## 🗑️ 移除的过时配置项

### 不再使用的配置项
- ❌ `CONTEXT_MESSAGE_COUNT` - 原单条检测的上下文消息数量（已改为批量检测）

由于现在所有检测都使用批量检测方法，不再需要单条检测的上下文消息配置。

## 📋 配置项使用统计

### 核心功能配置: 4项
- 消息回溯时间、管理员群、警告消息、禁言时长

### 白名单配置: 2项  
- 用户白名单、群聊白名单

### AI模型配置: 12项
- 基础模型配置(6项) + 增强配置(6项)

### 批量处理配置: 4项
- 队列速率、批量大小、文本长度限制、队列容量

### 总计: 22个有效配置项

所有配置项现在都已正确添加到 `_conf_schema.json` 文件中，并且代码与配置文件中的命名保持一致。
